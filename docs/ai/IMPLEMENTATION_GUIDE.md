# Agentic Control Implementation Guide

## Overview

This codebase implements and compares three different approaches to spacecraft control using a double integrator system. The key innovation is **agentic control** - where an AI agent uses physics-aware tools to make better control decisions.

---

## ğŸ”¬ Physics Integration

### Double Integrator System

The core physics is implemented in `01_basic_physics/double_integrator.py`:

```
Physics: áº = u (acceleration equals control force)
State: [position, velocity]
Dynamics:
  - position(t+1) = position(t) + velocity(t) * dt
  - velocity(t+1) = velocity(t) + control_force * dt
```

**Why Double Integrator?**
- **Simplest controllable system**: Easy to understand and verify
- **Spacecraft-like dynamics**: Represents basic spacecraft maneuvering
- **Known optimal solutions**: We can compare against theoretical optimum
- **Real physics**: Actual differential equations, not toy problems

### Physics Implementation Details

```python
class DoubleIntegrator:
    def step(self, control_force):
        # Clip control to physical limits
        u = np.clip(control_force, -self.max_force, self.max_force)
        
        # Exact integration for double integrator
        new_velocity = self.velocity + u * self.dt
        new_position = self.position + self.velocity * self.dt + 0.5 * u * self.dt**2
```

This is **real physics simulation** with:
- Force limits (like thruster constraints)
- Proper integration (not just toy math)
- State evolution over time
- Physical constraints

---

## ğŸ¤– Control Approaches Compared

### 1. PD Baseline (Classical Control)

**Location**: Implemented in test scripts as `PDController`

**How it works**:
```python
def get_action(self, position, velocity, target_pos, target_vel=0.0):
    pos_error = target_pos - position
    vel_error = target_vel - velocity
    action = kp * pos_error + kd * vel_error  # PD control law
    return np.clip(action, -1.0, 1.0)
```

**Physics**: Uses **control theory** - proven mathematical approach
- Proportional term: Corrects position error
- Derivative term: Prevents overshoot using velocity feedback
- **No AI involved** - pure physics-based control

### 2. Mock LLM (Direct AI Control)

**Location**: Implemented in test scripts as `MockLLMController`

**How it works**:
```python
def get_action(self, position, velocity, target_pos, target_vel=0.0):
    pos_error = target_pos - position
    vel_error = target_vel - velocity
    
    # Imperfect PD with noise (simulates LLM uncertainty)
    kp = 0.8 + np.random.normal(0, 0.1)  # Noisy gain
    kd = 1.5 + np.random.normal(0, 0.2)  # Noisy gain
    action = kp * pos_error + kd * vel_error
    action += np.random.normal(0, 0.05)  # Control noise
```

**Physics**: LLM tries to **directly output control actions**
- **Pros**: Can potentially learn complex behaviors
- **Cons**: No physics knowledge, prone to instability
- **Reality**: Most LLMs struggle with precise numerical control

### 3. Tool-Augmented (Agentic Control) â­

**Location**: `03_langgraph_tools/`

**How it works**: LLM uses **physics-aware tools** instead of direct control

```
LLM Reasoning â†’ Physics Tools â†’ Safe Control Action
```

This is the **core innovation** of your codebase!

---

## ğŸ› ï¸ Agentic Control Deep Dive

### What Makes It "Agentic"?

**Traditional AI**: LLM directly outputs numbers
```
LLM: "Apply force -0.3" â†’ Environment
```

**Agentic AI**: LLM uses tools like a human engineer would
```
LLM: "Let me analyze the error" â†’ ErrorAnalyzerTool â†’ "High urgency, need braking"
LLM: "Calculate optimal PID" â†’ PIDCalculatorTool â†’ "Force: -0.5, confidence: 0.8"
LLM: "Verify safety" â†’ SafetyVerifierTool â†’ "Safe, no adjustments needed"
LLM: "Execute -0.5 force"
```

### Physics-Aware Tools Implementation

**Location**: `03_langgraph_tools/control_tools.py`

#### 1. ErrorAnalyzerTool

```python
@tool
def analyze_errors(position: float, velocity: float, target_pos: float, target_vel: float) -> dict:
    """Analyze control errors and system state for spacecraft control."""
    
    pos_error = target_pos - position
    vel_error = target_vel - velocity
    
    # Physics-based analysis
    if pos_distance > 0.5:
        urgency = "high"
    elif pos_distance > 0.15:
        urgency = "medium"
    else:
        urgency = "low"
    
    # Stability analysis (physics-based)
    if pos_error * velocity > 0.1:  # Moving away from target
        stability = "unstable"
    else:
        stability = "stable"
```

**Physics Integration**: Uses **control theory concepts**:
- Error magnitude assessment
- Stability analysis (Lyapunov-like)
- Phase determination (approach/brake/fine-tune)

#### 2. PIDCalculatorTool

```python
@tool  
def calculate_pid_control(pos_error: float, vel_error: float, kp: float = 1.0, kd: float = 2.0) -> dict:
    """Calculate PID control action using proven control theory."""
    
    # Classical control theory
    p_term = kp * pos_error
    d_term = kd * vel_error  # Velocity is derivative of position
    
    raw_control = p_term + d_term
    control_action = np.clip(raw_control, -max_force, max_force)
```

**Physics Integration**: Implements **classical control theory**:
- PID control law (proven for double integrator)
- Anti-windup protection
- Confidence estimation based on error magnitude

#### 3. TrajectoryPlannerTool

```python
@tool
def plan_trajectory(current_pos: float, current_vel: float, target_pos: float) -> dict:
    """Plan optimal trajectory using physics-based trajectory generation."""
    
    # Physics: Double integrator optimal control
    pos_change = target_pos - current_pos
    
    # Bang-bang control estimation (optimal for double integrator)
    if pos_distance > 0.1:
        # Phase 1: Accelerate toward target
        accel_time = min(2.0, time_horizon * 0.4)
        accel_dir = 1.0 if pos_change > 0 else -1.0
        
        # Physics: kinematic equations
        mid_vel = current_vel + accel_dir * max_accel * accel_time
        mid_pos = current_pos + current_vel * accel_time + 0.5 * accel_dir * max_accel * accel_time**2
```

**Physics Integration**: Uses **optimal control theory**:
- Bang-bang control (provably optimal for double integrator)
- Kinematic equations for trajectory prediction
- Time-optimal path planning

#### 4. SafetyVerifierTool

```python
@tool
def verify_safety(control_action: float, current_pos: float, current_vel: float) -> dict:
    """Verify control action safety using physics-based prediction."""
    
    # Physics prediction: where will we be next?
    dt = 0.1
    next_vel = current_vel + control_action * dt
    next_pos = current_pos + current_vel * dt
    
    # Physics-based safety checks
    if abs(control_action) > 0.8 * max_force:
        warnings.append("High force magnitude - may cause oscillations")
    
    if current_vel * control_action > 0.3:  # Same direction, high magnitude
        warnings.append("Accelerating while already moving fast")
```

**Physics Integration**: Uses **forward simulation**:
- Predicts next state using physics equations
- Checks for constraint violations
- Prevents dangerous control actions

---

## ğŸŒŠ LangGraph Workflow

**Location**: `03_langgraph_tools/control_graph.py`

The agentic control uses a **structured workflow**:

```
1. observe_state â†’ 2. analyze_errors â†’ 3. plan_action â†’ 4. verify_safety â†’ 5. execute_action
```

### Workflow Details

```python
def build_control_graph():
    workflow = StateGraph(ControlState)
    
    # Physics-aware workflow
    workflow.add_node("observe_state", observe_state)
    workflow.add_node("analyze_errors", analyze_errors_node)    # Uses ErrorAnalyzerTool
    workflow.add_node("plan_action", plan_action_node)          # Uses PIDCalculatorTool/TrajectoryPlannerTool
    workflow.add_node("verify_safety", verify_safety_node)     # Uses SafetyVerifierTool
    workflow.add_node("execute_action", execute_action_node)   # Final control output
    
    # Define workflow edges
    workflow.add_edge("observe_state", "analyze_errors")
    workflow.add_edge("analyze_errors", "plan_action")
    workflow.add_edge("plan_action", "verify_safety")
    workflow.add_edge("verify_safety", "execute_action")
```

### State Management

```python
class ControlState(TypedDict):
    # Input physics state
    position: float
    velocity: float
    target_pos: float
    target_vel: float
    
    # Tool analysis results
    error_analysis: Dict     # From ErrorAnalyzerTool
    control_plan: Dict       # From PIDCalculatorTool/TrajectoryPlannerTool  
    safety_check: Dict       # From SafetyVerifierTool
    
    # Final output
    action: float
    confidence: float
    reasoning: str
```

---

## ğŸ¯ Key Physics Advantages

### Why Physics-Aware Tools Work Better

1. **Proven Control Theory**: Tools implement decades of control engineering research
2. **Physical Constraints**: Built-in understanding of force limits, stability, etc.
3. **Predictive Safety**: Forward simulation prevents dangerous actions
4. **Interpretable**: Each tool provides physics-based reasoning

### Performance Comparison

From your test results:

| Approach | Success Rate | Efficiency | Confidence | Physics Knowledge |
|----------|-------------|------------|------------|------------------|
| **Tool-Augmented** | 100% | 7.8 steps | **0.846** | âœ… Full physics integration |
| PD Baseline | 100% | 7.8 steps | 0.900 | âœ… Classical control theory |
| Mock LLM | 100% | 9.0 steps | 0.741 | âŒ No physics, just pattern matching |

**Key Insight**: Tool-Augmented achieves **classical control performance** while maintaining **high AI confidence** and **interpretable reasoning**.

---

## ğŸ“Š Visualization & Results

### What the Plots Show

**Location**: Generated in `results/figures/`

#### Trajectory Plots (`trajectory_*.png`)

Each plot shows **4 subplots**:

1. **Position vs Time**: How spacecraft moves toward target
   - X-axis: Time (seconds)
   - Y-axis: Position (meters)  
   - Shows convergence behavior

2. **Velocity vs Time**: How spacecraft velocity changes
   - Shows damping/oscillation behavior
   - Critical for stability analysis

3. **Control Actions vs Time**: Force commands over time
   - Shows control effort and smoothness
   - Red lines = force limits (Â±1.0)

4. **Phase Portrait**: Position vs Velocity
   - Shows system dynamics in phase space
   - Spiral toward origin = stable control
   - **Most important plot** for control analysis

#### Performance Summary (`performance_summary_*.png`)

Shows **6 comparison charts**:

1. **Success Rate**: Which approach works reliably
2. **Efficiency**: Average steps to reach target  
3. **Control Effort**: How much force is used
4. **Confidence Distribution**: AI confidence levels
5. **Position Accuracy**: Final position errors (boxplot)
6. **Velocity Accuracy**: Final velocity errors (boxplot)

---

## ğŸ—ï¸ Codebase Architecture

```
agentic_control_minimal/
â”œâ”€â”€ 01_basic_physics/          # Core physics simulation
â”‚   â”œâ”€â”€ double_integrator.py   # Physics engine
â”‚   â”œâ”€â”€ test_environment.py    # Physics verification
â”‚   â””â”€â”€ visualize_dynamics.py  # Basic plotting
â”œâ”€â”€ 02_direct_control/         # Direct LLM approaches  
â”‚   â”œâ”€â”€ simple_controller.py   # Mock LLM controller
â”‚   â”œâ”€â”€ llm_integration.py     # Real LLM APIs (vLLM, OpenAI)
â”‚   â”œâ”€â”€ rollout.py            # Training data collection
â”‚   â””â”€â”€ test_llm.py           # LLM testing framework
â”œâ”€â”€ 03_langgraph_tools/        # â­ AGENTIC CONTROL CORE
â”‚   â”œâ”€â”€ control_tools.py       # Physics-aware tools
â”‚   â”œâ”€â”€ control_graph.py       # LangGraph workflow
â”‚   â””â”€â”€ test_graph.py         # Comprehensive testing
â”œâ”€â”€ slurm/                     # HPC experiment framework
â”‚   â”œâ”€â”€ run_control_experiments.sh      # Main slurm job
â”‚   â”œâ”€â”€ experiment_runner.py            # Experiment orchestrator  
â”‚   â””â”€â”€ submit_experiments.sh           # Quick submission
â””â”€â”€ results/                   # Generated results
    â”œâ”€â”€ figures/              # Trajectory plots, performance summaries
    â”œâ”€â”€ data/                # Raw trajectory data (JSON)
    â””â”€â”€ reports/             # Analysis reports (Markdown)
```

---

## ğŸš€ How Physics Enables Better AI Control

### Traditional Approach Problems

```python
# Direct LLM Control (Problematic)
prompt = f"Position: {pos}, Velocity: {vel}, Target: {target}. Output force:"
force = llm(prompt)  # LLM guesses a number
```

**Issues**:
- No physics understanding
- Prone to instability  
- Hard to debug failures
- No safety guarantees

### Agentic Approach Solution

```python
# Physics-Aware Agentic Control
error_analysis = analyze_errors_tool(pos, vel, target)  # Physics-based analysis
if error_analysis['urgency'] == 'high':
    control_plan = plan_trajectory_tool(pos, vel, target)  # Optimal control theory
else:
    control_plan = calculate_pid_tool(error_analysis)      # Classical control
safety_check = verify_safety_tool(control_plan['action']) # Forward simulation
final_action = safety_check['adjusted_action']            # Safe, verified control
```

**Advantages**:
- âœ… Physics knowledge built-in
- âœ… Provably safe control
- âœ… Interpretable reasoning  
- âœ… Combines AI flexibility with physics rigor

---

## ğŸ¯ Future Extensions

### Aerospace Applications

The double integrator foundation scales to:

1. **3D Spacecraft Control**
   - Same physics principles
   - More complex state space
   - Attitude control integration

2. **Multi-Phase Missions**
   - Orbital transfers
   - Rendezvous and docking
   - Formation flying

3. **Constrained Operations**
   - Fuel optimization
   - Keep-out zones
   - Actuator failures

### Advanced Agentic Features

1. **Adaptive Tool Selection**
   - Simple scenarios â†’ PID tools
   - Complex scenarios â†’ Trajectory planning tools
   - Emergency â†’ Safety-first tools

2. **Multi-Agent Coordination**
   - Multiple spacecraft
   - Distributed decision making
   - Communication delays

3. **Learning-Enhanced Tools**
   - Tools that improve with experience
   - Physics-informed neural networks
   - Hybrid symbolic-neural reasoning

---

## ğŸ“š Key Takeaways

### What Makes This "Agentic Control"

1. **Tool Usage**: AI uses physics tools like human engineers
2. **Structured Reasoning**: Systematic workflow (observe â†’ analyze â†’ plan â†’ verify â†’ execute)
3. **Physics Integration**: Tools embody control theory knowledge  
4. **Interpretable**: Each step provides clear reasoning
5. **Safe**: Physics-based verification prevents dangerous actions

### Why This Approach Works

- **Best of Both Worlds**: AI flexibility + Physics rigor
- **Scalable**: Physics principles apply to complex systems
- **Debuggable**: Clear reasoning chain for failure analysis
- **Safe**: Built-in physics constraints and verification
- **Interpretable**: Domain experts can understand decisions

### Research Impact

This demonstrates that **agentic AI can effectively use physics-based tools** for control tasks, opening new possibilities for:
- Autonomous spacecraft operations
- Physics-informed AI systems  
- Interpretable control systems
- Safe AI for physical systems

---

*This implementation guide shows how physics and AI can be effectively combined through agentic control, providing both performance and interpretability for spacecraft control applications.*